"""
Target Problem:
---------------
* A classifier for the diagnosis of Autism Spectrum Disorder (ASD)

Proposed Solution (Machine Learning Pipeline):
----------------------------------------------
* SelectKBest Algorithm -> Adaptive Boosting (Base: Decision Tree)

Input to Proposed Solution:
---------------------------
* Directories of training and testing data in csv file format
* These two types of data should be stored in n x m pattern in csv file format.

  Typical Example:
  ----------------
  n x m samples in training csv file (n number of samples, m - 1 number of features, ground truth labels at last column)
  k x s samples in testing csv file (k number of samples, s number of features)

* These data set files are ready by load_data() function.
* For comprehensive information about input format, please check the section
  "Data Sets and Usage Format of Source Codes" in README.md file on github.

Output of Proposed Solution:
----------------------------
* Predictions generated by learning model for testing set
* They are stored in "submission.csv" file.

Code Owner:
-----------
* Copyright © Team 11. All rights reserved.
* Copyright © Istanbul Technical University, Learning From Data Spring 2019. All rights reserved. """

import csv
import numpy as np
import pandas as pd
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.ensemble import AdaBoostClassifier


def load_data(train_file, test_file):

    """
    The method reads train and test data from their dataset files.
    Then, it splits train data into features and labels.

    Parameters
    ----------
    train_file: directory of the file in which train data set is located
    test_file: directory of the file in which test data set is located

    """

    data = np.asarray(pd.read_csv(train_file, header=0))
    data_ts = np.asarray(pd.read_csv(test_file, header=0))

    x_tra = data[:, :-1]
    y_tra = data[:, -1]

    return x_tra, y_tra, data_ts


def preprocessing(x_tra, y_tra, x_tst):

    """
    * The method computes chi square value for each feature, and
      chooses top 190 features with highest chi square value.
    * This is performed by using SelectKBest() feature selection algorithm.

    Parameters
    ----------
    x_tra: features of training data
    y_tra: labels of training data
    x_tst: features of test data

    """

    selector = SelectKBest(chi2, 190)
    selector.fit(x_tra, y_tra)
    x_tra_new = selector.transform(x_tra)
    x_tst_new = selector.transform(x_tst)

    return x_tra_new, x_tst_new


def train_model(x_tra, y_tra):

    """
    The method creates a learning model and trains it by using training data.

    Parameters
    ----------
    x_tra: features of training data
    y_tra: labels of training data
    """

    clf1 = AdaBoostClassifier(n_estimators=300, random_state=1)
    clf1.fit(x_tra, y_tra)
    return clf1


def predict(x_tst, model):

    """
    The method predicts labels for testing data samples by using trained learning model.

    Parameters
    ----------
    x_tst: features of testing data
    model: trained learning model
    """

    predictions = model.predict(x_tst)
    return predictions


def write_output(predictions):

    order = np.arange(1, 81)
    order.shape = (80, 1)
    predictions.shape = (80, 1)

    pred = np.concatenate((order, predictions), axis=1).astype(dtype=np.int)
    with open('submission.csv', 'w') as csvFile:
        writer = csv.writer(csvFile)
        writer.writerow(("ID", "Predicted"))
        writer.writerows(pred)
    csvFile.close()


# ********** MAIN PROGRAM ********** #

x_tra, y_tra, x_tst = load_data("train.csv", "test.csv")
x_tra_new, x_tst_new = preprocessing(x_tra, y_tra, x_tst)

model = train_model(x_tra_new, y_tra)
predictions = predict(x_tst_new, model)
write_output(predictions)
