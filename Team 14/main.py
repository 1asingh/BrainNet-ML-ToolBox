"""
Target Problem:
---------------
* A classifier for the diagnosis of Autism Spectrum Disorder (ASD)

Proposed Solution (Machine Learning Pipeline):
----------------------------------------------
* PCA -> Random Forest

Input to Proposed Solution:
---------------------------
* Directories of training and testing data in csv file format
* These two types of data should be stored in n x m pattern in csv file format.

  Typical Example:
  ----------------
  n x m samples in training csv file (n number of samples, m - 1 number of features, ground truth labels at last column)
  k x s samples in testing csv file (k number of samples, s number of features)

* These data set files are ready by load_data() function.
* For comprehensive information about input format, please check the section
  "Data Sets and Usage Format of Source Codes" in README.md file on github.

Output of Proposed Solution:
----------------------------
* Predictions generated by learning model for testing set
* They are stored in "submission.csv" file.

Code Owner:
-----------
* Copyright © Team 14. All rights reserved.
* Copyright © Istanbul Technical University, Learning From Data Spring 2019. All rights reserved. """

import pandas as pd
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier


def load_data():

    """
    The method reads train and test data from data set files.
    Then, it splits train data into features and labels.
    """

    train = pd.read_csv("train.csv")
    test = pd.read_csv("test.csv")

    train_x = train.iloc[:, :-1]
    train_y = train.iloc[:, -1]
    return train_x, train_y, test


def preprocessing(X, y, test):

    """
    * The method at first eliminates nan-valued columns.
      (There is no nan-valued feature column, it is redundant operation.)

    * Then, first 100 samples from train data are chosen as training set.
      The remains 20 samples from train data are regarded as testing data.
      In other words, the learning model will be trained with first 100 training samples, not all of them.

    * Finally, it performs pca on training and testing data to reduce the dimension.

    Parameters
    ----------
    X: features of training data
    y: labels of training data
    test: features of testing data
    """

    X = X.dropna(axis=1, how='all')
    test = test.dropna(axis=1, how='all')

    x_train = X[0:100][:]
    x_test = X[100:120][:]
    y_train = y.iloc[0:100]
    y_test = y.iloc[100:120]

    pca = PCA(n_components=80)
    x_train = pca.fit_transform(x_train)
    x_test = pca.transform(x_test)
    test = pca.transform(test)

    return x_train, x_test, y_train, y_test, test


def train_model(x_train, y_train):
    """
    The method creates a learning model and trains it by using first 100 training samples.

    Parameters
    ----------
    x_train: features of first 100 training samples
    y_train: labels of first 100 training samples
    """

    classifier = RandomForestClassifier(n_estimators=1000, random_state=50)
    classifier.fit(x_train, y_train)
    return classifier


def predict(classifier, x_train_test, real_test):

    """
    The method makes two predictions:
       - First prediction is for last 20 samples of training data
       - Second prediction is for testing data

    Parameters
    ----------
    classifier: trained model
    x_train_test: features of last 20 samples of training data
    real_test: features of testing data
    """

    predictions1 = classifier.predict(x_train_test)
    predictions2 = classifier.predict(real_test)
    return predictions1, predictions2


def write_output(y_predTest):

    f = open('submission.csv', 'w', encoding="utf-8")
    tempstr = "ID,Predicted\n"
    f.write(tempstr)

    # print(y_predTest)

    i = 1
    for y in y_predTest:
        tempstr = str(i)
        tempstr += ","
        tempstr += str(y)
        tempstr += "\n"

        i += 1
        f.write(tempstr)
    f.close


# ********** MAIN PROGRAM ********** #

X, y, test = load_data()
x_train, x_train_test, y_train, y_train_test, real_test = preprocessing(X, y, test)

classifier = train_model(x_train, y_train)
train_test_pred, real_test_pred = predict(classifier, x_train_test, real_test)
write_output(real_test_pred)

"""
*********************************************************
The codes below are used to investigate the performance *
of trained model on last 20 samples of training data.   *
*********************************************************

print(confusion_matrix(y_train_test, train_test_pred))
print(classification_report(y_train_test, train_test_pred))
print(accuracy_score(y_train_test, train_test_pred))

"""
