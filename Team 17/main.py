"""
Target Problem:
---------------
* A classifier for the diagnosis of Autism Spectrum Disorder (ASD)

Proposed Solution (Machine Learning Pipeline):
----------------------------------------------
* LDA -> Voting Classifier

Input to Proposed Solution:
---------------------------
* Directories of training and testing data in csv file format
* These two types of data should be stored in n x m pattern in csv file format.

  Typical Example:
  ----------------
  n x m samples in training csv file (n number of samples, m - 1 number of features, ground truth labels at last column)
  k x s samples in testing csv file (k number of samples, s number of features)

* These data set files are ready by load_data() function.
* For comprehensive information about input format, please check the section
  "Data Sets and Usage Format of Source Codes" in README.md file on github.

Output of Proposed Solution:
----------------------------
* Predictions generated by learning model for testing set
* They are stored in "submission.csv" file.

Code Owner:
-----------
* Copyright © Team 17. All rights reserved.
* Copyright © Istanbul Technical University, Learning From Data Spring 2019. All rights reserved. """

import numpy as np
import pandas as pd

from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import SGDClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.ensemble import RandomForestClassifier as RFC, VotingClassifier, GradientBoostingClassifier as GBC


def load_data(tra_file_path, test_file_path):

    """
    The method reads train and test data from data set files in dataframe format.
    When reading them, it benefits from directory paths of the files passed by the parameters.
    Then, it converts them into numpy arrays and returns them.

    Parameters
    ----------
    tra_file_path: directory of training data
    test_file_path: directory of testing data
    """

    x_tra = pd.read_csv(tra_file_path, sep=',')
    x_tst = pd.read_csv(test_file_path, sep=',')
    return np.array(x_tra), np.array(x_tst)


def dimension_reduction(train_x, train_y, test_x):

    """
    Linear Discriminant Analysis (LDA) can be used to both reduce the dimension and train a learning model.
    In this point, it is used as dimension reducer. It is like supervised version of PCA.
    This method benefits from LDA to reduce the dimension train and test data.

    Parameters
    ----------
    train_x: features of training data
    train_y: labels of training data
    test_x: features of testing data
    """

    lda = LDA(n_components=1)
    lda.fit(train_x, train_y)

    train_x_reduced = lda.transform(train_x)
    test_x_reduced = lda.transform(test_x)
    return train_x_reduced, test_x_reduced


def train_model(train, target):

    """
    The method creates 5 different learning models.
    Then, these 5 models are combined in a voting classifier.
    That voting classifier is trained with training data.

    Parameters
    ----------
    train: features of training data
    target: labels of training data
    """

    clf1 = SVC(kernel='rbf', gamma=5, C=80, random_state=1)
    clf2 = GaussianNB()
    clf3 = GBC(n_estimators=20, learning_rate=1.0, random_state=1)
    clf4 = RFC(n_estimators=20, random_state=1)
    clf5 = SGDClassifier(tol=1e-3, random_state=1)

    ensemble = VotingClassifier(estimators=[('svm', clf1), ('nb', clf2), ('gbc', clf3), ('rfc', clf4), ('sgd', clf5)],
                                voting='hard')
    ensemble.fit(train, target)
    return ensemble


def predict(model, x_test):

    """
    The method predicts labels for testing data samples.

    Parameters
    ----------
    model: trained voting classifier
    x_test: features of testing data
    """
    return model.predict(x_test)


def write_output(predictions):

    results = np.zeros((len(predictions), 2))
    for i in range(len(predictions)):
        results[i][0] = i + 1
        results[i][1] = predictions[i]

    results = results.astype(int)
    predictions = predictions.astype(int)

    results = pd.DataFrame(data=results, columns=['ID', 'Predicted'])
    results.to_csv('submission.csv', index=False, sep=',')


def main(tra_file_path, test_file_path):

    train_data, test_features = load_data(tra_file_path, test_file_path)
    train_features = train_data[:, 0:len(train_data[0]) - 1]
    train_labels = train_data[:, len(train_data[0]) - 1]

    x_train, x_test = dimension_reduction(train_features, train_labels, test_features)
    clf = train_model(x_train, train_labels)
    preds = predict(clf, x_test)
    write_output(preds)


main('train.csv', 'test.csv')
