"""
Target Problem:
---------------
* A classifier for the diagnosis of Autism Spectrum Disorder (ASD)

Proposed Solution (Machine Learning Pipeline):
----------------------------------------------
* Min-Max Scaling -> PCA -> Bagging Classifier (Base: KNN)

Input to Proposed Solution:
---------------------------
* Directories of training and testing data in csv file format
* These two types of data should be stored in n x m pattern in csv file format.

  Typical Example:
  ----------------
  n x m samples in training csv file (n number of samples, m - 1 number of features, ground truth labels at last column)
  k x s samples in testing csv file (k number of samples, s number of features)

* These data set files are ready by load_data() function.
* For comprehensive information about input format, please check the section
  "Data Sets and Usage Format of Source Codes" in README.md file on github.

Output of Proposed Solution:
----------------------------
* Predictions generated by learning model for testing set
* They are stored in "submission.csv" file.

Code Owner:
-----------
* Copyright © Team 9. All rights reserved.
* Copyright © Istanbul Technical University, Learning From Data Spring 2019. All rights reserved. """

import csv
import pandas as pd

from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA

from sklearn.ensemble import BaggingClassifier
from sklearn.neighbors import KNeighborsClassifier


def load_data():

    """
    The method reads train and test data from data files.
    Then, it splits train data into features and labels.
    """

    train_data = pd.read_csv("train.csv")
    test_data = pd.read_csv("test.csv")
    train_x = train_data.iloc[:, 0:595]
    train_y = train_data.iloc[:, -1]

    return train_x, train_y, test_data


def preprocessing(train_x, test_x):

    """
    The method at first performs min-max scaling on train and testing data.
    Then, it reduces dimension of train and test data by using pca.

    Parameters
    ----------
    train_x: features of train data
    test_x: features of test data

    """

    scaler = MinMaxScaler()
    scl_train_x = scaler.fit_transform(train_x)
    scl_test_x = scaler.transform(test_x)

    pca = PCA(n_components=5)
    pca.fit(scl_train_x)
    pca_train_x = pca.transform(scl_train_x)
    pca_test_x = pca.transform(scl_test_x)

    return pca_train_x, pca_test_x


def train_model(train_x, train_y):

    """
    The method trains a learning model by using training data.

    Parameters
    ----------
    train_x: features of training data
    train_y: labels of training data

    """
    model = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, random_state=4)
    model.fit(train_x, train_y)
    return model


def predict(model, test_x):

    """
    The method predicts labels for testing samples by using trained model.

    Parameters
    ----------
    model: trained model
    test_x: features of testing data
    """
    return model.predict(test_x)


def write_output(predictions):

    with open("submission.csv", mode='w+', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["ID", "Predicted"])

    count = 1
    for pred in predictions:
        with open("submission.csv", mode='a', newline='') as file:
            writer = csv.writer(file)
            writer.writerow([count, pred])
            count += 1


# ********** MAIN PROGRAM ********** #

train_x, train_y, test_x = load_data()
pca_train_x, pca_test_x = preprocessing(train_x, test_x)
model = train_model(pca_train_x, train_y)
predictions = predict(model, pca_test_x)
write_output(predictions)
